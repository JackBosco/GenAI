{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "I am checking if a fruit is ripe or not or something idk\n",
    "\n",
    "### 1. Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('apple_quality.csv', index_col='A_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploritory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe: (4001, 8)\n",
      "Data types of each column:\n",
      "Size           float64\n",
      "Weight         float64\n",
      "Sweetness      float64\n",
      "Crunchiness    float64\n",
      "Juiciness      float64\n",
      "Ripeness       float64\n",
      "Acidity         object\n",
      "Quality         object\n",
      "dtype: object\n",
      "Summary statistics of numerical columns:\n",
      "              Size       Weight    Sweetness  Crunchiness    Juiciness  \\\n",
      "count  4000.000000  4000.000000  4000.000000  4000.000000  4000.000000   \n",
      "mean     -0.503015    -0.989547    -0.470479     0.985478     0.512118   \n",
      "std       1.928059     1.602507     1.943441     1.402757     1.930286   \n",
      "min      -7.151703    -7.149848    -6.894485    -6.055058    -5.961897   \n",
      "25%      -1.816765    -2.011770    -1.738425     0.062764    -0.801286   \n",
      "50%      -0.513703    -0.984736    -0.504758     0.998249     0.534219   \n",
      "75%       0.805526     0.030976     0.801922     1.894234     1.835976   \n",
      "max       6.406367     5.790714     6.374916     7.619852     7.364403   \n",
      "\n",
      "          Ripeness  \n",
      "count  4000.000000  \n",
      "mean      0.498277  \n",
      "std       1.874427  \n",
      "min      -5.864599  \n",
      "25%      -0.771677  \n",
      "50%       0.503445  \n",
      "75%       1.766212  \n",
      "max       7.237837  \n",
      "Number of missing values in each column:\n",
      "Size           1\n",
      "Weight         1\n",
      "Sweetness      1\n",
      "Crunchiness    1\n",
      "Juiciness      1\n",
      "Ripeness       1\n",
      "Acidity        0\n",
      "Quality        1\n",
      "dtype: int64\n",
      "Quality\n",
      "good    2004\n",
      "bad     1996\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Crunchiness</th>\n",
       "      <th>Juiciness</th>\n",
       "      <th>Ripeness</th>\n",
       "      <th>Acidity</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>-3.970049</td>\n",
       "      <td>-2.512336</td>\n",
       "      <td>5.346330</td>\n",
       "      <td>-1.012009</td>\n",
       "      <td>1.844900</td>\n",
       "      <td>0.329840</td>\n",
       "      <td>-0.491590483</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>-1.195217</td>\n",
       "      <td>-2.839257</td>\n",
       "      <td>3.664059</td>\n",
       "      <td>1.588232</td>\n",
       "      <td>0.853286</td>\n",
       "      <td>0.867530</td>\n",
       "      <td>-0.722809367</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>-0.292024</td>\n",
       "      <td>-1.351282</td>\n",
       "      <td>-1.738429</td>\n",
       "      <td>-0.342616</td>\n",
       "      <td>2.838636</td>\n",
       "      <td>-0.038033</td>\n",
       "      <td>2.621636473</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>-0.657196</td>\n",
       "      <td>-2.271627</td>\n",
       "      <td>1.324874</td>\n",
       "      <td>-0.097875</td>\n",
       "      <td>3.637970</td>\n",
       "      <td>-3.413761</td>\n",
       "      <td>0.790723217</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1.364217</td>\n",
       "      <td>-1.296612</td>\n",
       "      <td>-0.384658</td>\n",
       "      <td>-0.553006</td>\n",
       "      <td>3.030874</td>\n",
       "      <td>-1.303849</td>\n",
       "      <td>0.501984036</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996.0</th>\n",
       "      <td>-0.293118</td>\n",
       "      <td>1.949253</td>\n",
       "      <td>-0.204020</td>\n",
       "      <td>-0.640196</td>\n",
       "      <td>0.024523</td>\n",
       "      <td>-1.087900</td>\n",
       "      <td>1.854235285</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997.0</th>\n",
       "      <td>-2.634515</td>\n",
       "      <td>-2.138247</td>\n",
       "      <td>-2.440461</td>\n",
       "      <td>0.657223</td>\n",
       "      <td>2.199709</td>\n",
       "      <td>4.763859</td>\n",
       "      <td>-1.334611391</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998.0</th>\n",
       "      <td>-4.008004</td>\n",
       "      <td>-1.779337</td>\n",
       "      <td>2.366397</td>\n",
       "      <td>-0.200329</td>\n",
       "      <td>2.161435</td>\n",
       "      <td>0.214488</td>\n",
       "      <td>-2.229719806</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999.0</th>\n",
       "      <td>0.278540</td>\n",
       "      <td>-1.715505</td>\n",
       "      <td>0.121217</td>\n",
       "      <td>-1.154075</td>\n",
       "      <td>1.266677</td>\n",
       "      <td>-0.776571</td>\n",
       "      <td>1.599796456</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Created_by_Nidula_Elgiriyewithana</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4001 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Size    Weight  Sweetness  Crunchiness  Juiciness  Ripeness  \\\n",
       "A_id                                                                      \n",
       "0.0    -3.970049 -2.512336   5.346330    -1.012009   1.844900  0.329840   \n",
       "1.0    -1.195217 -2.839257   3.664059     1.588232   0.853286  0.867530   \n",
       "2.0    -0.292024 -1.351282  -1.738429    -0.342616   2.838636 -0.038033   \n",
       "3.0    -0.657196 -2.271627   1.324874    -0.097875   3.637970 -3.413761   \n",
       "4.0     1.364217 -1.296612  -0.384658    -0.553006   3.030874 -1.303849   \n",
       "...          ...       ...        ...          ...        ...       ...   \n",
       "3996.0 -0.293118  1.949253  -0.204020    -0.640196   0.024523 -1.087900   \n",
       "3997.0 -2.634515 -2.138247  -2.440461     0.657223   2.199709  4.763859   \n",
       "3998.0 -4.008004 -1.779337   2.366397    -0.200329   2.161435  0.214488   \n",
       "3999.0  0.278540 -1.715505   0.121217    -1.154075   1.266677 -0.776571   \n",
       "NaN          NaN       NaN        NaN          NaN        NaN       NaN   \n",
       "\n",
       "                                  Acidity Quality  \n",
       "A_id                                               \n",
       "0.0                          -0.491590483    good  \n",
       "1.0                          -0.722809367    good  \n",
       "2.0                           2.621636473     bad  \n",
       "3.0                           0.790723217    good  \n",
       "4.0                           0.501984036    good  \n",
       "...                                   ...     ...  \n",
       "3996.0                        1.854235285    good  \n",
       "3997.0                       -1.334611391     bad  \n",
       "3998.0                       -2.229719806    good  \n",
       "3999.0                        1.599796456    good  \n",
       "NaN     Created_by_Nidula_Elgiriyewithana     NaN  \n",
       "\n",
       "[4001 rows x 8 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the dataframe\n",
    "print(\"Shape of the dataframe:\", df.shape)\n",
    "\n",
    "# Check the data types of each column\n",
    "print(\"Data types of each column:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check the summary statistics of the numerical columns\n",
    "print(\"Summary statistics of numerical columns:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check the number of missing values in each column\n",
    "print(\"Number of missing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# check the number of good and bad apples\n",
    "print(df['Quality'].value_counts())\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing\n",
    "\n",
    "getting the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Crunchiness</th>\n",
       "      <th>Juiciness</th>\n",
       "      <th>Ripeness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>-3.970049</td>\n",
       "      <td>-2.512336</td>\n",
       "      <td>5.346330</td>\n",
       "      <td>-1.012009</td>\n",
       "      <td>1.844900</td>\n",
       "      <td>0.329840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>-1.195217</td>\n",
       "      <td>-2.839257</td>\n",
       "      <td>3.664059</td>\n",
       "      <td>1.588232</td>\n",
       "      <td>0.853286</td>\n",
       "      <td>0.867530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>-0.292024</td>\n",
       "      <td>-1.351282</td>\n",
       "      <td>-1.738429</td>\n",
       "      <td>-0.342616</td>\n",
       "      <td>2.838636</td>\n",
       "      <td>-0.038033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>-0.657196</td>\n",
       "      <td>-2.271627</td>\n",
       "      <td>1.324874</td>\n",
       "      <td>-0.097875</td>\n",
       "      <td>3.637970</td>\n",
       "      <td>-3.413761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1.364217</td>\n",
       "      <td>-1.296612</td>\n",
       "      <td>-0.384658</td>\n",
       "      <td>-0.553006</td>\n",
       "      <td>3.030874</td>\n",
       "      <td>-1.303849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995.0</th>\n",
       "      <td>0.059386</td>\n",
       "      <td>-1.067408</td>\n",
       "      <td>-3.714549</td>\n",
       "      <td>0.473052</td>\n",
       "      <td>1.697986</td>\n",
       "      <td>2.244055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996.0</th>\n",
       "      <td>-0.293118</td>\n",
       "      <td>1.949253</td>\n",
       "      <td>-0.204020</td>\n",
       "      <td>-0.640196</td>\n",
       "      <td>0.024523</td>\n",
       "      <td>-1.087900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997.0</th>\n",
       "      <td>-2.634515</td>\n",
       "      <td>-2.138247</td>\n",
       "      <td>-2.440461</td>\n",
       "      <td>0.657223</td>\n",
       "      <td>2.199709</td>\n",
       "      <td>4.763859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998.0</th>\n",
       "      <td>-4.008004</td>\n",
       "      <td>-1.779337</td>\n",
       "      <td>2.366397</td>\n",
       "      <td>-0.200329</td>\n",
       "      <td>2.161435</td>\n",
       "      <td>0.214488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999.0</th>\n",
       "      <td>0.278540</td>\n",
       "      <td>-1.715505</td>\n",
       "      <td>0.121217</td>\n",
       "      <td>-1.154075</td>\n",
       "      <td>1.266677</td>\n",
       "      <td>-0.776571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Size    Weight  Sweetness  Crunchiness  Juiciness  Ripeness\n",
       "A_id                                                                   \n",
       "0.0    -3.970049 -2.512336   5.346330    -1.012009   1.844900  0.329840\n",
       "1.0    -1.195217 -2.839257   3.664059     1.588232   0.853286  0.867530\n",
       "2.0    -0.292024 -1.351282  -1.738429    -0.342616   2.838636 -0.038033\n",
       "3.0    -0.657196 -2.271627   1.324874    -0.097875   3.637970 -3.413761\n",
       "4.0     1.364217 -1.296612  -0.384658    -0.553006   3.030874 -1.303849\n",
       "...          ...       ...        ...          ...        ...       ...\n",
       "3995.0  0.059386 -1.067408  -3.714549     0.473052   1.697986  2.244055\n",
       "3996.0 -0.293118  1.949253  -0.204020    -0.640196   0.024523 -1.087900\n",
       "3997.0 -2.634515 -2.138247  -2.440461     0.657223   2.199709  4.763859\n",
       "3998.0 -4.008004 -1.779337   2.366397    -0.200329   2.161435  0.214488\n",
       "3999.0  0.278540 -1.715505   0.121217    -1.154075   1.266677 -0.776571\n",
       "\n",
       "[4000 rows x 6 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Preprocess your data, prepare you input, output vectors / matrices.\n",
    "\n",
    "# drop na\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "inputs = df.loc[:, 'Size':'Ripeness'] # type: ignore\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Getting the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_good</th>\n",
       "      <th>is_bad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995.0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997.0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_good  is_bad\n",
       "A_id                   \n",
       "0.0           1       0\n",
       "1.0           1       0\n",
       "2.0           0       1\n",
       "3.0           1       0\n",
       "4.0           1       0\n",
       "...         ...     ...\n",
       "3995.0        0       1\n",
       "3996.0        1       0\n",
       "3997.0        0       1\n",
       "3998.0        1       0\n",
       "3999.0        1       0\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_good'] = df['Quality'].apply(lambda x: 1 if x == 'good' else 0)\n",
    "df['is_bad'] = df['Quality'].apply(lambda x: 1 if x == 'bad' else 0)\n",
    "\n",
    "targets = df.loc[:, 'is_good':'is_bad']\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Normalize the inputs between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Crunchiness</th>\n",
       "      <th>Juiciness</th>\n",
       "      <th>Ripeness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.234669</td>\n",
       "      <td>0.358370</td>\n",
       "      <td>0.922484</td>\n",
       "      <td>0.368781</td>\n",
       "      <td>0.585819</td>\n",
       "      <td>0.472770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.439331</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>0.795706</td>\n",
       "      <td>0.558928</td>\n",
       "      <td>0.511408</td>\n",
       "      <td>0.513807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.505948</td>\n",
       "      <td>0.448092</td>\n",
       "      <td>0.388567</td>\n",
       "      <td>0.417732</td>\n",
       "      <td>0.660388</td>\n",
       "      <td>0.444693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.479014</td>\n",
       "      <td>0.376971</td>\n",
       "      <td>0.619422</td>\n",
       "      <td>0.435629</td>\n",
       "      <td>0.720370</td>\n",
       "      <td>0.187052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.628107</td>\n",
       "      <td>0.452317</td>\n",
       "      <td>0.490589</td>\n",
       "      <td>0.402347</td>\n",
       "      <td>0.674814</td>\n",
       "      <td>0.348084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995.0</th>\n",
       "      <td>0.531867</td>\n",
       "      <td>0.470029</td>\n",
       "      <td>0.239644</td>\n",
       "      <td>0.477379</td>\n",
       "      <td>0.574794</td>\n",
       "      <td>0.618866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996.0</th>\n",
       "      <td>0.505867</td>\n",
       "      <td>0.703146</td>\n",
       "      <td>0.504203</td>\n",
       "      <td>0.395971</td>\n",
       "      <td>0.449218</td>\n",
       "      <td>0.364566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997.0</th>\n",
       "      <td>0.333173</td>\n",
       "      <td>0.387278</td>\n",
       "      <td>0.335661</td>\n",
       "      <td>0.490846</td>\n",
       "      <td>0.612443</td>\n",
       "      <td>0.811182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998.0</th>\n",
       "      <td>0.231869</td>\n",
       "      <td>0.415014</td>\n",
       "      <td>0.697913</td>\n",
       "      <td>0.428137</td>\n",
       "      <td>0.609571</td>\n",
       "      <td>0.463966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999.0</th>\n",
       "      <td>0.548031</td>\n",
       "      <td>0.419946</td>\n",
       "      <td>0.528713</td>\n",
       "      <td>0.358392</td>\n",
       "      <td>0.542429</td>\n",
       "      <td>0.388327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Size    Weight  Sweetness  Crunchiness  Juiciness  Ripeness\n",
       "A_id                                                                   \n",
       "0.0     0.234669  0.358370   0.922484     0.368781   0.585819  0.472770\n",
       "1.0     0.439331  0.333107   0.795706     0.558928   0.511408  0.513807\n",
       "2.0     0.505948  0.448092   0.388567     0.417732   0.660388  0.444693\n",
       "3.0     0.479014  0.376971   0.619422     0.435629   0.720370  0.187052\n",
       "4.0     0.628107  0.452317   0.490589     0.402347   0.674814  0.348084\n",
       "...          ...       ...        ...          ...        ...       ...\n",
       "3995.0  0.531867  0.470029   0.239644     0.477379   0.574794  0.618866\n",
       "3996.0  0.505867  0.703146   0.504203     0.395971   0.449218  0.364566\n",
       "3997.0  0.333173  0.387278   0.335661     0.490846   0.612443  0.811182\n",
       "3998.0  0.231869  0.415014   0.697913     0.428137   0.609571  0.463966\n",
       "3999.0  0.548031  0.419946   0.528713     0.358392   0.542429  0.388327\n",
       "\n",
       "[4000 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = (inputs + inputs.min().abs()) / (inputs.max() + inputs.min().abs())\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Creating the neural network classifier\n",
    "\n",
    "1 hidden layer of size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (fc1): Linear(in_features=6, out_features=256, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the neural network classifier\n",
    "class Classifier(nn.Module):\n",
    "\tdef __init__(self, input_size, hidden_size, output_size):\n",
    "\t\tsuper(Classifier, self).__init__()\n",
    "\t\tself.fc1 = nn.Linear(input_size, hidden_size)\n",
    "\t\tself.relu = nn.ReLU()\n",
    "\t\tself.fc2 = nn.Linear(hidden_size, 128)\n",
    "\t\tself.dropout = nn.Dropout(0.1)\n",
    "\t\tself.fc3 = nn.Linear(128, 64)\n",
    "\t\tself.fc4 = nn.Linear(64, output_size)\n",
    "\t\tself.softmax = nn.Softmax()\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.relu(self.fc1(x))\n",
    "\t\t#x = self.dropout(x)\n",
    "\t\tx = self.relu(self.fc2(x))\n",
    "\t\tx = self.relu(self.fc3(x))\n",
    "\t\tx = self.fc4(x)\n",
    "\t\treturn x\n",
    "\n",
    "# Set the input size, hidden size, and output size\n",
    "input_size = inputs.shape[1]\n",
    "hidden_size = 256\n",
    "output_size = targets.shape[1]\n",
    "\n",
    "# Create an instance of the classifier\n",
    "classifier = Classifier(input_size, hidden_size, output_size)\n",
    "\n",
    "# Print the classifier architecture\n",
    "print(classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Use CrossEntropyLoss and the Adam optimizer to train your Neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = inputs.sample(frac=0.9)\n",
    "test_inputs = inputs.drop(train_inputs.index)\n",
    "train_targets = targets.iloc[train_inputs.index]\n",
    "test_targets = targets.iloc[test_inputs.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.00015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.691\n",
      "[1,   400] loss: 0.685\n",
      "[1,   600] loss: 0.669\n",
      "[1,   800] loss: 0.656\n",
      "[1,  1000] loss: 0.617\n",
      "[1,  1200] loss: 0.597\n",
      "[1,  1400] loss: 0.558\n",
      "[1,  1600] loss: 0.576\n",
      "[1,  1800] loss: 0.569\n",
      "[1,  2000] loss: 0.550\n",
      "[1,  2200] loss: 0.600\n",
      "[1,  2400] loss: 0.528\n",
      "[1,  2600] loss: 0.519\n",
      "[1,  2800] loss: 0.468\n",
      "[1,  3000] loss: 0.555\n",
      "[1,  3200] loss: 0.552\n",
      "[1,  3400] loss: 0.482\n",
      "[1,  3600] loss: 0.489\n",
      "[2,   200] loss: 0.494\n",
      "[2,   400] loss: 0.519\n",
      "[2,   600] loss: 0.490\n",
      "[2,   800] loss: 0.519\n",
      "[2,  1000] loss: 0.476\n",
      "[2,  1200] loss: 0.447\n",
      "[2,  1400] loss: 0.457\n",
      "[2,  1600] loss: 0.475\n",
      "[2,  1800] loss: 0.502\n",
      "[2,  2000] loss: 0.459\n",
      "[2,  2200] loss: 0.539\n",
      "[2,  2400] loss: 0.455\n",
      "[2,  2600] loss: 0.436\n",
      "[2,  2800] loss: 0.393\n",
      "[2,  3000] loss: 0.477\n",
      "[2,  3200] loss: 0.482\n",
      "[2,  3400] loss: 0.431\n",
      "[2,  3600] loss: 0.437\n",
      "[3,   200] loss: 0.438\n",
      "[3,   400] loss: 0.458\n",
      "[3,   600] loss: 0.438\n",
      "[3,   800] loss: 0.445\n",
      "[3,  1000] loss: 0.418\n",
      "[3,  1200] loss: 0.365\n",
      "[3,  1400] loss: 0.420\n",
      "[3,  1600] loss: 0.412\n",
      "[3,  1800] loss: 0.474\n",
      "[3,  2000] loss: 0.392\n",
      "[3,  2200] loss: 0.502\n",
      "[3,  2400] loss: 0.404\n",
      "[3,  2600] loss: 0.385\n",
      "[3,  2800] loss: 0.359\n",
      "[3,  3000] loss: 0.405\n",
      "[3,  3200] loss: 0.444\n",
      "[3,  3400] loss: 0.405\n",
      "[3,  3600] loss: 0.405\n",
      "[4,   200] loss: 0.408\n",
      "[4,   400] loss: 0.428\n",
      "[4,   600] loss: 0.410\n",
      "[4,   800] loss: 0.395\n",
      "[4,  1000] loss: 0.390\n",
      "[4,  1200] loss: 0.334\n",
      "[4,  1400] loss: 0.405\n",
      "[4,  1600] loss: 0.381\n",
      "[4,  1800] loss: 0.459\n",
      "[4,  2000] loss: 0.352\n",
      "[4,  2200] loss: 0.475\n",
      "[4,  2400] loss: 0.374\n",
      "[4,  2600] loss: 0.358\n",
      "[4,  2800] loss: 0.346\n",
      "[4,  3000] loss: 0.361\n",
      "[4,  3200] loss: 0.412\n",
      "[4,  3400] loss: 0.392\n",
      "[4,  3600] loss: 0.380\n",
      "[5,   200] loss: 0.386\n",
      "[5,   400] loss: 0.414\n",
      "[5,   600] loss: 0.392\n",
      "[5,   800] loss: 0.362\n",
      "[5,  1000] loss: 0.372\n",
      "[5,  1200] loss: 0.319\n",
      "[5,  1400] loss: 0.400\n",
      "[5,  1600] loss: 0.365\n",
      "[5,  1800] loss: 0.447\n",
      "[5,  2000] loss: 0.325\n",
      "[5,  2200] loss: 0.453\n",
      "[5,  2400] loss: 0.353\n",
      "[5,  2600] loss: 0.341\n",
      "[5,  2800] loss: 0.335\n",
      "[5,  3000] loss: 0.333\n",
      "[5,  3200] loss: 0.386\n",
      "[5,  3400] loss: 0.384\n",
      "[5,  3600] loss: 0.362\n",
      "[6,   200] loss: 0.371\n",
      "[6,   400] loss: 0.409\n",
      "[6,   600] loss: 0.379\n",
      "[6,   800] loss: 0.341\n",
      "[6,  1000] loss: 0.354\n",
      "[6,  1200] loss: 0.310\n",
      "[6,  1400] loss: 0.395\n",
      "[6,  1600] loss: 0.354\n",
      "[6,  1800] loss: 0.436\n",
      "[6,  2000] loss: 0.306\n",
      "[6,  2200] loss: 0.437\n",
      "[6,  2400] loss: 0.338\n",
      "[6,  2600] loss: 0.328\n",
      "[6,  2800] loss: 0.329\n",
      "[6,  3000] loss: 0.314\n",
      "[6,  3200] loss: 0.368\n",
      "[6,  3400] loss: 0.380\n",
      "[6,  3600] loss: 0.350\n",
      "[7,   200] loss: 0.360\n",
      "[7,   400] loss: 0.406\n",
      "[7,   600] loss: 0.367\n",
      "[7,   800] loss: 0.324\n",
      "[7,  1000] loss: 0.339\n",
      "[7,  1200] loss: 0.306\n",
      "[7,  1400] loss: 0.386\n",
      "[7,  1600] loss: 0.343\n",
      "[7,  1800] loss: 0.430\n",
      "[7,  2000] loss: 0.292\n",
      "[7,  2200] loss: 0.425\n",
      "[7,  2400] loss: 0.331\n",
      "[7,  2600] loss: 0.320\n",
      "[7,  2800] loss: 0.323\n",
      "[7,  3000] loss: 0.300\n",
      "[7,  3200] loss: 0.348\n",
      "[7,  3400] loss: 0.375\n",
      "[7,  3600] loss: 0.339\n",
      "[8,   200] loss: 0.351\n",
      "[8,   400] loss: 0.407\n",
      "[8,   600] loss: 0.357\n",
      "[8,   800] loss: 0.311\n",
      "[8,  1000] loss: 0.326\n",
      "[8,  1200] loss: 0.303\n",
      "[8,  1400] loss: 0.378\n",
      "[8,  1600] loss: 0.333\n",
      "[8,  1800] loss: 0.423\n",
      "[8,  2000] loss: 0.282\n",
      "[8,  2200] loss: 0.410\n",
      "[8,  2400] loss: 0.326\n",
      "[8,  2600] loss: 0.313\n",
      "[8,  2800] loss: 0.319\n",
      "[8,  3000] loss: 0.292\n",
      "[8,  3200] loss: 0.335\n",
      "[8,  3400] loss: 0.370\n",
      "[8,  3600] loss: 0.330\n",
      "[9,   200] loss: 0.345\n",
      "[9,   400] loss: 0.406\n",
      "[9,   600] loss: 0.352\n",
      "[9,   800] loss: 0.302\n",
      "[9,  1000] loss: 0.315\n",
      "[9,  1200] loss: 0.300\n",
      "[9,  1400] loss: 0.372\n",
      "[9,  1600] loss: 0.325\n",
      "[9,  1800] loss: 0.421\n",
      "[9,  2000] loss: 0.277\n",
      "[9,  2200] loss: 0.399\n",
      "[9,  2400] loss: 0.320\n",
      "[9,  2600] loss: 0.307\n",
      "[9,  2800] loss: 0.316\n",
      "[9,  3000] loss: 0.284\n",
      "[9,  3200] loss: 0.327\n",
      "[9,  3400] loss: 0.364\n",
      "[9,  3600] loss: 0.323\n",
      "[10,   200] loss: 0.340\n",
      "[10,   400] loss: 0.405\n",
      "[10,   600] loss: 0.347\n",
      "[10,   800] loss: 0.295\n",
      "[10,  1000] loss: 0.309\n",
      "[10,  1200] loss: 0.297\n",
      "[10,  1400] loss: 0.369\n",
      "[10,  1600] loss: 0.315\n",
      "[10,  1800] loss: 0.417\n",
      "[10,  2000] loss: 0.268\n",
      "[10,  2200] loss: 0.390\n",
      "[10,  2400] loss: 0.315\n",
      "[10,  2600] loss: 0.303\n",
      "[10,  2800] loss: 0.312\n",
      "[10,  3000] loss: 0.276\n",
      "[10,  3200] loss: 0.321\n",
      "[10,  3400] loss: 0.363\n",
      "[10,  3600] loss: 0.316\n",
      "[11,   200] loss: 0.338\n",
      "[11,   400] loss: 0.405\n",
      "[11,   600] loss: 0.344\n",
      "[11,   800] loss: 0.288\n",
      "[11,  1000] loss: 0.304\n",
      "[11,  1200] loss: 0.293\n",
      "[11,  1400] loss: 0.367\n",
      "[11,  1600] loss: 0.310\n",
      "[11,  1800] loss: 0.416\n",
      "[11,  2000] loss: 0.262\n",
      "[11,  2200] loss: 0.382\n",
      "[11,  2400] loss: 0.310\n",
      "[11,  2600] loss: 0.298\n",
      "[11,  2800] loss: 0.308\n",
      "[11,  3000] loss: 0.272\n",
      "[11,  3200] loss: 0.313\n",
      "[11,  3400] loss: 0.358\n",
      "[11,  3600] loss: 0.310\n",
      "[12,   200] loss: 0.332\n",
      "[12,   400] loss: 0.404\n",
      "[12,   600] loss: 0.337\n",
      "[12,   800] loss: 0.281\n",
      "[12,  1000] loss: 0.298\n",
      "[12,  1200] loss: 0.290\n",
      "[12,  1400] loss: 0.362\n",
      "[12,  1600] loss: 0.302\n",
      "[12,  1800] loss: 0.413\n",
      "[12,  2000] loss: 0.254\n",
      "[12,  2200] loss: 0.373\n",
      "[12,  2400] loss: 0.306\n",
      "[12,  2600] loss: 0.293\n",
      "[12,  2800] loss: 0.305\n",
      "[12,  3000] loss: 0.264\n",
      "[12,  3200] loss: 0.306\n",
      "[12,  3400] loss: 0.353\n",
      "[12,  3600] loss: 0.304\n",
      "[13,   200] loss: 0.328\n",
      "[13,   400] loss: 0.403\n",
      "[13,   600] loss: 0.332\n",
      "[13,   800] loss: 0.277\n",
      "[13,  1000] loss: 0.292\n",
      "[13,  1200] loss: 0.285\n",
      "[13,  1400] loss: 0.357\n",
      "[13,  1600] loss: 0.298\n",
      "[13,  1800] loss: 0.408\n",
      "[13,  2000] loss: 0.249\n",
      "[13,  2200] loss: 0.365\n",
      "[13,  2400] loss: 0.300\n",
      "[13,  2600] loss: 0.287\n",
      "[13,  2800] loss: 0.302\n",
      "[13,  3000] loss: 0.260\n",
      "[13,  3200] loss: 0.300\n",
      "[13,  3400] loss: 0.349\n",
      "[13,  3600] loss: 0.296\n",
      "[14,   200] loss: 0.325\n",
      "[14,   400] loss: 0.401\n",
      "[14,   600] loss: 0.326\n",
      "[14,   800] loss: 0.272\n",
      "[14,  1000] loss: 0.285\n",
      "[14,  1200] loss: 0.281\n",
      "[14,  1400] loss: 0.351\n",
      "[14,  1600] loss: 0.292\n",
      "[14,  1800] loss: 0.401\n",
      "[14,  2000] loss: 0.242\n",
      "[14,  2200] loss: 0.356\n",
      "[14,  2400] loss: 0.296\n",
      "[14,  2600] loss: 0.277\n",
      "[14,  2800] loss: 0.296\n",
      "[14,  3000] loss: 0.255\n",
      "[14,  3200] loss: 0.289\n",
      "[14,  3400] loss: 0.342\n",
      "[14,  3600] loss: 0.289\n",
      "[15,   200] loss: 0.321\n",
      "[15,   400] loss: 0.398\n",
      "[15,   600] loss: 0.320\n",
      "[15,   800] loss: 0.265\n",
      "[15,  1000] loss: 0.281\n",
      "[15,  1200] loss: 0.276\n",
      "[15,  1400] loss: 0.342\n",
      "[15,  1600] loss: 0.283\n",
      "[15,  1800] loss: 0.395\n",
      "[15,  2000] loss: 0.234\n",
      "[15,  2200] loss: 0.347\n",
      "[15,  2400] loss: 0.292\n",
      "[15,  2600] loss: 0.267\n",
      "[15,  2800] loss: 0.293\n",
      "[15,  3000] loss: 0.248\n",
      "[15,  3200] loss: 0.281\n",
      "[15,  3400] loss: 0.338\n",
      "[15,  3600] loss: 0.279\n",
      "[16,   200] loss: 0.319\n",
      "[16,   400] loss: 0.395\n",
      "[16,   600] loss: 0.314\n",
      "[16,   800] loss: 0.260\n",
      "[16,  1000] loss: 0.276\n",
      "[16,  1200] loss: 0.266\n",
      "[16,  1400] loss: 0.334\n",
      "[16,  1600] loss: 0.274\n",
      "[16,  1800] loss: 0.390\n",
      "[16,  2000] loss: 0.226\n",
      "[16,  2200] loss: 0.337\n",
      "[16,  2400] loss: 0.284\n",
      "[16,  2600] loss: 0.257\n",
      "[16,  2800] loss: 0.286\n",
      "[16,  3000] loss: 0.244\n",
      "[16,  3200] loss: 0.271\n",
      "[16,  3400] loss: 0.332\n",
      "[16,  3600] loss: 0.270\n",
      "[17,   200] loss: 0.315\n",
      "[17,   400] loss: 0.389\n",
      "[17,   600] loss: 0.310\n",
      "[17,   800] loss: 0.255\n",
      "[17,  1000] loss: 0.269\n",
      "[17,  1200] loss: 0.259\n",
      "[17,  1400] loss: 0.325\n",
      "[17,  1600] loss: 0.265\n",
      "[17,  1800] loss: 0.382\n",
      "[17,  2000] loss: 0.218\n",
      "[17,  2200] loss: 0.326\n",
      "[17,  2400] loss: 0.280\n",
      "[17,  2600] loss: 0.248\n",
      "[17,  2800] loss: 0.280\n",
      "[17,  3000] loss: 0.236\n",
      "[17,  3200] loss: 0.261\n",
      "[17,  3400] loss: 0.325\n",
      "[17,  3600] loss: 0.260\n",
      "[18,   200] loss: 0.310\n",
      "[18,   400] loss: 0.385\n",
      "[18,   600] loss: 0.305\n",
      "[18,   800] loss: 0.247\n",
      "[18,  1000] loss: 0.264\n",
      "[18,  1200] loss: 0.250\n",
      "[18,  1400] loss: 0.315\n",
      "[18,  1600] loss: 0.257\n",
      "[18,  1800] loss: 0.371\n",
      "[18,  2000] loss: 0.211\n",
      "[18,  2200] loss: 0.317\n",
      "[18,  2400] loss: 0.273\n",
      "[18,  2600] loss: 0.238\n",
      "[18,  2800] loss: 0.273\n",
      "[18,  3000] loss: 0.231\n",
      "[18,  3200] loss: 0.247\n",
      "[18,  3400] loss: 0.322\n",
      "[18,  3600] loss: 0.249\n",
      "[19,   200] loss: 0.304\n",
      "[19,   400] loss: 0.376\n",
      "[19,   600] loss: 0.298\n",
      "[19,   800] loss: 0.238\n",
      "[19,  1000] loss: 0.256\n",
      "[19,  1200] loss: 0.244\n",
      "[19,  1400] loss: 0.301\n",
      "[19,  1600] loss: 0.246\n",
      "[19,  1800] loss: 0.360\n",
      "[19,  2000] loss: 0.201\n",
      "[19,  2200] loss: 0.305\n",
      "[19,  2400] loss: 0.267\n",
      "[19,  2600] loss: 0.230\n",
      "[19,  2800] loss: 0.264\n",
      "[19,  3000] loss: 0.226\n",
      "[19,  3200] loss: 0.236\n",
      "[19,  3400] loss: 0.314\n",
      "[19,  3600] loss: 0.237\n",
      "[20,   200] loss: 0.298\n",
      "[20,   400] loss: 0.371\n",
      "[20,   600] loss: 0.292\n",
      "[20,   800] loss: 0.230\n",
      "[20,  1000] loss: 0.248\n",
      "[20,  1200] loss: 0.234\n",
      "[20,  1400] loss: 0.292\n",
      "[20,  1600] loss: 0.237\n",
      "[20,  1800] loss: 0.349\n",
      "[20,  2000] loss: 0.192\n",
      "[20,  2200] loss: 0.297\n",
      "[20,  2400] loss: 0.259\n",
      "[20,  2600] loss: 0.218\n",
      "[20,  2800] loss: 0.257\n",
      "[20,  3000] loss: 0.222\n",
      "[20,  3200] loss: 0.224\n",
      "[20,  3400] loss: 0.311\n",
      "[20,  3600] loss: 0.231\n",
      "[21,   200] loss: 0.291\n",
      "[21,   400] loss: 0.364\n",
      "[21,   600] loss: 0.286\n",
      "[21,   800] loss: 0.222\n",
      "[21,  1000] loss: 0.240\n",
      "[21,  1200] loss: 0.228\n",
      "[21,  1400] loss: 0.278\n",
      "[21,  1600] loss: 0.227\n",
      "[21,  1800] loss: 0.340\n",
      "[21,  2000] loss: 0.182\n",
      "[21,  2200] loss: 0.287\n",
      "[21,  2400] loss: 0.254\n",
      "[21,  2600] loss: 0.209\n",
      "[21,  2800] loss: 0.249\n",
      "[21,  3000] loss: 0.218\n",
      "[21,  3200] loss: 0.214\n",
      "[21,  3400] loss: 0.304\n",
      "[21,  3600] loss: 0.222\n",
      "[22,   200] loss: 0.283\n",
      "[22,   400] loss: 0.359\n",
      "[22,   600] loss: 0.279\n",
      "[22,   800] loss: 0.218\n",
      "[22,  1000] loss: 0.234\n",
      "[22,  1200] loss: 0.222\n",
      "[22,  1400] loss: 0.267\n",
      "[22,  1600] loss: 0.218\n",
      "[22,  1800] loss: 0.327\n",
      "[22,  2000] loss: 0.172\n",
      "[22,  2200] loss: 0.281\n",
      "[22,  2400] loss: 0.249\n",
      "[22,  2600] loss: 0.201\n",
      "[22,  2800] loss: 0.242\n",
      "[22,  3000] loss: 0.216\n",
      "[22,  3200] loss: 0.206\n",
      "[22,  3400] loss: 0.300\n",
      "[22,  3600] loss: 0.216\n",
      "[23,   200] loss: 0.277\n",
      "[23,   400] loss: 0.350\n",
      "[23,   600] loss: 0.274\n",
      "[23,   800] loss: 0.212\n",
      "[23,  1000] loss: 0.228\n",
      "[23,  1200] loss: 0.216\n",
      "[23,  1400] loss: 0.256\n",
      "[23,  1600] loss: 0.212\n",
      "[23,  1800] loss: 0.316\n",
      "[23,  2000] loss: 0.164\n",
      "[23,  2200] loss: 0.274\n",
      "[23,  2400] loss: 0.243\n",
      "[23,  2600] loss: 0.191\n",
      "[23,  2800] loss: 0.238\n",
      "[23,  3000] loss: 0.211\n",
      "[23,  3200] loss: 0.202\n",
      "[23,  3400] loss: 0.297\n",
      "[23,  3600] loss: 0.210\n",
      "[24,   200] loss: 0.272\n",
      "[24,   400] loss: 0.346\n",
      "[24,   600] loss: 0.270\n",
      "[24,   800] loss: 0.205\n",
      "[24,  1000] loss: 0.225\n",
      "[24,  1200] loss: 0.211\n",
      "[24,  1400] loss: 0.247\n",
      "[24,  1600] loss: 0.206\n",
      "[24,  1800] loss: 0.307\n",
      "[24,  2000] loss: 0.160\n",
      "[24,  2200] loss: 0.268\n",
      "[24,  2400] loss: 0.238\n",
      "[24,  2600] loss: 0.185\n",
      "[24,  2800] loss: 0.231\n",
      "[24,  3000] loss: 0.207\n",
      "[24,  3200] loss: 0.196\n",
      "[24,  3400] loss: 0.293\n",
      "[24,  3600] loss: 0.204\n",
      "[25,   200] loss: 0.270\n",
      "[25,   400] loss: 0.339\n",
      "[25,   600] loss: 0.264\n",
      "[25,   800] loss: 0.200\n",
      "[25,  1000] loss: 0.218\n",
      "[25,  1200] loss: 0.205\n",
      "[25,  1400] loss: 0.240\n",
      "[25,  1600] loss: 0.203\n",
      "[25,  1800] loss: 0.301\n",
      "[25,  2000] loss: 0.152\n",
      "[25,  2200] loss: 0.265\n",
      "[25,  2400] loss: 0.232\n",
      "[25,  2600] loss: 0.179\n",
      "[25,  2800] loss: 0.228\n",
      "[25,  3000] loss: 0.205\n",
      "[25,  3200] loss: 0.194\n",
      "[25,  3400] loss: 0.287\n",
      "[25,  3600] loss: 0.201\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(zip(train_inputs.values, train_targets.values), 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        inputs = Tensor(inputs)\n",
    "        labels = Tensor(labels)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = classifier.forward(inputs)# Get outputs here\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:  # print every 2005 mini-batches\n",
    "            print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test the Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: good  is 86.6 %\n",
      "Accuracy for class: bad   is 96.4 %\n"
     ]
    }
   ],
   "source": [
    "from torch import no_grad\n",
    "from torch import max as torch_max\n",
    "\n",
    "# prepare to count predictions for each class\n",
    "classes = ['good', 'bad']\n",
    "correct_pred = {'good': 0, 'bad': 0}\n",
    "total_pred = {'good': 0, 'bad': 0}\n",
    "\n",
    "# again no gradients needed\n",
    "with no_grad():\n",
    "    for data in zip(test_inputs.values, test_targets.values):\n",
    "        target, label = data\n",
    "        target = Tensor(target)\n",
    "        label = Tensor(label)\n",
    "        output = classifier(target)\n",
    "        pred = torch_max(output, 0)[1] # get the index of the max log-probability\n",
    "        label = torch_max(label, 0)[1]\n",
    "        # collect the correct predictions for each class\n",
    "        if label == pred:\n",
    "\t\t\t# increment correct predictions counter\n",
    "            correct_pred[classes[pred]] += 1\n",
    "\t\t# increment total predictions counter\n",
    "        total_pred[classes[pred]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy =  correct_count / total_pred[classname] * 100# Calculate the accuracy for each class\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
